{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LTVh5gH91kL1",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/frbernad/.local/share/virtualenvs/itba-nlp-kqtWtpaJ/lib/python3.11/site-packages (1.25.0)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.0\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.1.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Requirement already satisfied: pandas in /Users/frbernad/.local/share/virtualenvs/itba-nlp-kqtWtpaJ/lib/python3.11/site-packages (2.0.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/frbernad/.local/share/virtualenvs/itba-nlp-kqtWtpaJ/lib/python3.11/site-packages (from pandas) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/frbernad/.local/share/virtualenvs/itba-nlp-kqtWtpaJ/lib/python3.11/site-packages (from pandas) (2023.3)\r\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/frbernad/.local/share/virtualenvs/itba-nlp-kqtWtpaJ/lib/python3.11/site-packages (from pandas) (2023.3)\r\n",
      "Requirement already satisfied: numpy>=1.21.0 in /Users/frbernad/.local/share/virtualenvs/itba-nlp-kqtWtpaJ/lib/python3.11/site-packages (from pandas) (1.25.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /Users/frbernad/.local/share/virtualenvs/itba-nlp-kqtWtpaJ/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\r\n",
      "^C\r\n",
      "\u001B[31mERROR: Operation cancelled by user\u001B[0m\u001B[31m\r\n",
      "\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.0\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.1.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Requirement already satisfied: plotly in /Users/frbernad/.local/share/virtualenvs/itba-nlp-kqtWtpaJ/lib/python3.11/site-packages (5.15.0)\r\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /Users/frbernad/.local/share/virtualenvs/itba-nlp-kqtWtpaJ/lib/python3.11/site-packages (from plotly) (8.2.2)\r\n",
      "Requirement already satisfied: packaging in /Users/frbernad/.local/share/virtualenvs/itba-nlp-kqtWtpaJ/lib/python3.11/site-packages (from plotly) (23.1)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.0\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.1.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Requirement already satisfied: pydantic in /Users/frbernad/.local/share/virtualenvs/itba-nlp-kqtWtpaJ/lib/python3.11/site-packages (1.10.9)\r\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/frbernad/.local/share/virtualenvs/itba-nlp-kqtWtpaJ/lib/python3.11/site-packages (from pydantic) (4.6.3)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.0\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.1.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Requirement already satisfied: pyyaml in /Users/frbernad/.local/share/virtualenvs/itba-nlp-kqtWtpaJ/lib/python3.11/site-packages (6.0)\r\n",
      "^C\r\n",
      "\u001B[31mERROR: Operation cancelled by user\u001B[0m\u001B[31m\r\n",
      "\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.0\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.1.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Collecting nltk\r\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.5/1.5 MB\u001B[0m \u001B[31m10.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting click\r\n",
      "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m96.6/96.6 kB\u001B[0m \u001B[31m8.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting joblib\r\n",
      "  Downloading joblib-1.3.0-py3-none-any.whl (301 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m301.9/301.9 kB\u001B[0m \u001B[31m11.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting regex>=2021.8.3\r\n",
      "  Downloading regex-2023.6.3-cp311-cp311-macosx_11_0_arm64.whl (288 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m289.0/289.0 kB\u001B[0m \u001B[31m12.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting tqdm\r\n",
      "  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m77.1/77.1 kB\u001B[0m \u001B[31m8.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hInstalling collected packages: tqdm, regex, joblib, click, nltk\r\n",
      "Successfully installed click-8.1.3 joblib-1.3.0 nltk-3.8.1 regex-2023.6.3 tqdm-4.65.0\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.0\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.1.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Collecting wordcloud\r\n",
      "  Downloading wordcloud-1.9.2.tar.gz (222 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m222.8/222.8 kB\u001B[0m \u001B[31m4.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25hRequirement already satisfied: numpy>=1.6.1 in /Users/frbernad/.local/share/virtualenvs/itba-nlp-kqtWtpaJ/lib/python3.11/site-packages (from wordcloud) (1.25.0)\r\n",
      "Collecting pillow\r\n",
      "  Downloading Pillow-9.5.0-cp311-cp311-macosx_11_0_arm64.whl (3.1 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.1/3.1 MB\u001B[0m \u001B[31m14.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting matplotlib\r\n",
      "  Downloading matplotlib-3.7.1-cp311-cp311-macosx_11_0_arm64.whl (7.3 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m7.3/7.3 MB\u001B[0m \u001B[31m13.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting contourpy>=1.0.1\r\n",
      "  Downloading contourpy-1.1.0-cp311-cp311-macosx_11_0_arm64.whl (229 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m229.3/229.3 kB\u001B[0m \u001B[31m13.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting cycler>=0.10\r\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\r\n",
      "Collecting fonttools>=4.22.0\r\n",
      "  Downloading fonttools-4.40.0-cp311-cp311-macosx_10_9_universal2.whl (2.5 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.5/2.5 MB\u001B[0m \u001B[31m13.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting kiwisolver>=1.0.1\r\n",
      "  Downloading kiwisolver-1.4.4-cp311-cp311-macosx_11_0_arm64.whl (63 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m63.1/63.1 kB\u001B[0m \u001B[31m8.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: packaging>=20.0 in /Users/frbernad/.local/share/virtualenvs/itba-nlp-kqtWtpaJ/lib/python3.11/site-packages (from matplotlib->wordcloud) (23.1)\r\n",
      "Collecting pyparsing>=2.3.1\r\n",
      "  Downloading pyparsing-3.1.0-py3-none-any.whl (102 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m102.6/102.6 kB\u001B[0m \u001B[31m9.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: python-dateutil>=2.7 in /Users/frbernad/.local/share/virtualenvs/itba-nlp-kqtWtpaJ/lib/python3.11/site-packages (from matplotlib->wordcloud) (2.8.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /Users/frbernad/.local/share/virtualenvs/itba-nlp-kqtWtpaJ/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\r\n",
      "Building wheels for collected packages: wordcloud\r\n",
      "  Building wheel for wordcloud (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for wordcloud: filename=wordcloud-1.9.2-cp311-cp311-macosx_12_0_arm64.whl size=153430 sha256=7ac5f4fa49ddfed9cd613f3932472cdd42741f2dc8a49417b824c1e5fc0d15cb\r\n",
      "  Stored in directory: /Users/frbernad/Library/Caches/pip/wheels/3f/c6/5a/89824e1846baaa6d6d54b3a7b1e7deecc9ae6e7ed30a1c8b0e\r\n",
      "Successfully built wordcloud\r\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib, wordcloud\r\n",
      "Successfully installed contourpy-1.1.0 cycler-0.11.0 fonttools-4.40.0 kiwisolver-1.4.4 matplotlib-3.7.1 pillow-9.5.0 pyparsing-3.1.0 wordcloud-1.9.2\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.0\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.1.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Requirement already satisfied: matplotlib in /Users/frbernad/.local/share/virtualenvs/itba-nlp-kqtWtpaJ/lib/python3.11/site-packages (3.7.1)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/frbernad/.local/share/virtualenvs/itba-nlp-kqtWtpaJ/lib/python3.11/site-packages (from matplotlib) (1.1.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/frbernad/.local/share/virtualenvs/itba-nlp-kqtWtpaJ/lib/python3.11/site-packages (from matplotlib) (0.11.0)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/frbernad/.local/share/virtualenvs/itba-nlp-kqtWtpaJ/lib/python3.11/site-packages (from matplotlib) (4.40.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/frbernad/.local/share/virtualenvs/itba-nlp-kqtWtpaJ/lib/python3.11/site-packages (from matplotlib) (1.4.4)\r\n",
      "Requirement already satisfied: numpy>=1.20 in /Users/frbernad/.local/share/virtualenvs/itba-nlp-kqtWtpaJ/lib/python3.11/site-packages (from matplotlib) (1.25.0)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/frbernad/.local/share/virtualenvs/itba-nlp-kqtWtpaJ/lib/python3.11/site-packages (from matplotlib) (23.1)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/frbernad/.local/share/virtualenvs/itba-nlp-kqtWtpaJ/lib/python3.11/site-packages (from matplotlib) (9.5.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/frbernad/.local/share/virtualenvs/itba-nlp-kqtWtpaJ/lib/python3.11/site-packages (from matplotlib) (3.1.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/frbernad/.local/share/virtualenvs/itba-nlp-kqtWtpaJ/lib/python3.11/site-packages (from matplotlib) (2.8.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /Users/frbernad/.local/share/virtualenvs/itba-nlp-kqtWtpaJ/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.0\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.1.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Collecting torch\r\n",
      "  Downloading torch-2.0.1-cp311-none-macosx_11_0_arm64.whl (55.8 MB)\r\n",
      "\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m55.8/55.8 MB\u001B[0m \u001B[31m14.3 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m00:01\u001B[0m"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!sudo apt install -y --no-install-recommends g++ protobuf-compiler libprotobuf-dev\n",
    "!pip install gcld3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "71xVdhWe40br"
   },
   "outputs": [],
   "source": [
    "import gcld3\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import re\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gTDrQxo0__U_"
   },
   "outputs": [],
   "source": [
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "S9SVbuaf420Q"
   },
   "outputs": [],
   "source": [
    "COLUMNS = ['tweet', 'likes', 'retweet_count', 'user_screen_name', 'user_description', 'user_followers_count']\n",
    "LANG = 'en'\n",
    "TW_USERNAME_REGEX = r\"@[a-zA-Z0-9_]{0,15}\"\n",
    "URL_REGEX = r\"\\b(https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9][\" \\\n",
    "            r\"a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]+\\.[^\\s]{2,\" \\\n",
    "            r\"}|www\\.[a-zA-Z0-9]+\\.[^\\s]{2,})\\b\"\n",
    "SPACES_REGEX = r\"\\s+\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z4xHHZiW92HD"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "GOOGLE_DRIVE_BASE_DIR = \"/content/drive/MyDrive/ITBA/Quinto Año/Segundo Cuatrimestre/NLP/TP\"\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F_8qbPI-45eN",
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "def get_selected_columns(df, columns):\n",
    "    return df[columns]\n",
    "\n",
    "\n",
    "def delete_hashtag_symbol(df):\n",
    "    df['tweet'] = df['tweet'].replace('#', '', regex=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def delete_twitter_username(df):\n",
    "    df['tweet'] = df['tweet'].replace(TW_USERNAME_REGEX, '', regex=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def delete_urls(df):\n",
    "    df['tweet'] = df['tweet'].replace(URL_REGEX, '', regex=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def delete_multiple_spaces(df):\n",
    "    df['tweet'] = df['tweet'].replace(SPACES_REGEX, '', regex=True)\n",
    "\n",
    "\n",
    "def is_lang(row, detector, lang='en'):\n",
    "    prediction = detector.FindLanguage(text=row['tweet'])\n",
    "    if prediction.language == lang and prediction.is_reliable:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def filter_by_language(df, lang='en'):\n",
    "    detector = gcld3.NNetLanguageIdentifier(min_num_bytes=50, max_num_bytes=2048)\n",
    "\n",
    "    mask = df.apply(is_lang, axis=1, detector=detector, lang=lang)\n",
    "    return df[mask]\n",
    "\n",
    "\n",
    "def is_feeling(row, sia, feeling, threshold):\n",
    "    sentiment_scores = sia.polarity_scores(row['tweet'])\n",
    "    if sentiment_scores[feeling] > threshold:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def filter_by_sentiment(df, feeling, threshold=0.4):\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "    mask = df.apply(is_feeling, axis=1, sia=sia, feeling=feeling, threshold=threshold)\n",
    "    return df[mask]\n",
    "\n",
    "\n",
    "def is_relevant(row, min_likes, min_retweets):\n",
    "    try:\n",
    "        likes = float(row['likes'])\n",
    "        retweets = float(row['retweet_count'])\n",
    "        if likes > min_likes or retweets > min_retweets:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "\n",
    "def filter_by_relevance(df, min_likes, min_retweets):\n",
    "    mask = df.apply(is_relevant, axis=1, min_likes=min_likes, min_retweets=min_retweets)\n",
    "    return df[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Tweets filtering and processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trump_df = pd.read_csv(f\"{GOOGLE_DRIVE_BASE_DIR}/hashtag_donaldtrump.csv\", sep=',', lineterminator='\\n',\n",
    "                       parse_dates=True, low_memory=False)\n",
    "biden_df = pd.read_csv(f\"{GOOGLE_DRIVE_BASE_DIR}/hashtag_joebiden.csv\", sep=',', lineterminator='\\n',\n",
    "                       parse_dates=True, low_memory=False)\n",
    "\n",
    "trump_tweets_count = len(trump_df)\n",
    "biden_tweets_count = len(biden_df)\n",
    "\n",
    "print(f'Total Trump Tweets: {trump_tweets_count}')\n",
    "print(f'Total Biden Tweets: {biden_tweets_count}')\n",
    "\n",
    "# Filtro de campos de interes\n",
    "trump_df = get_selected_columns(trump_df, COLUMNS)\n",
    "biden_df = get_selected_columns(biden_df, COLUMNS)\n",
    "\n",
    "# Filtro por longitud\n",
    "trump_df = trump_df[trump_df['tweet'].str.len() >= 50]\n",
    "biden_df = biden_df[biden_df['tweet'].str.len() >= 50]\n",
    "\n",
    "# Filtro por contenido\n",
    "# Links\n",
    "trump_df['tweet'] = trump_df['tweet'].replace(URL_REGEX, '', regex=True)\n",
    "biden_df['tweet'] = biden_df['tweet'].replace(URL_REGEX, '', regex=True)\n",
    "# Arrobas de respuesta o mencion\n",
    "trump_df['tweet'] = trump_df['tweet'].replace(TW_USERNAME_REGEX, '', regex=True)\n",
    "biden_df['tweet'] = biden_df['tweet'].replace(TW_USERNAME_REGEX, '', regex=True)\n",
    "# Espacios en blanco de mas\n",
    "trump_df['tweet'] = trump_df['tweet'].replace(SPACES_REGEX, ' ', regex=True)\n",
    "biden_df['tweet'] = biden_df['tweet'].replace(SPACES_REGEX, ' ', regex=True)\n",
    "# Caracteres inválidos\n",
    "trump_df['tweet'] = trump_df['tweet'].replace(\"&amp;\", '', regex=True)\n",
    "biden_df['tweet'] = biden_df['tweet'].replace(\"&amp;\", '', regex=True)\n",
    "# Simbolo de hashtag\n",
    "trump_df['tweet'] = trump_df['tweet'].replace(\"#\", '', regex=True)\n",
    "biden_df['tweet'] = biden_df['tweet'].replace(\"#\", '', regex=True)\n",
    "# Filtro por relevancia\n",
    "print(f'\\nTrump tweets mean')\n",
    "print(trump_df[['likes', 'retweet_count']].mean())\n",
    "print(f'\\nTrump tweets max')\n",
    "print(trump_df[['likes', 'retweet_count']].max())\n",
    "\n",
    "print(f'\\nBiden tweets mean')\n",
    "print(biden_df[['likes', 'retweet_count']].mean())\n",
    "print(f'\\nBiden tweets max')\n",
    "print(biden_df[['likes', 'retweet_count']].max())\n",
    "\n",
    "trump_df = filter_by_relevance(trump_df, min_likes=10, min_retweets=10)\n",
    "biden_df = filter_by_relevance(biden_df, min_likes=10, min_retweets=10)\n",
    "\n",
    "print(f\"Filtered trump tweets: {len(trump_df)}\")\n",
    "print(f\"Filtered biden tweets: {len(biden_df)}\")\n",
    "\n",
    "# Lenguage Ingles\n",
    "trump_df = filter_by_language(trump_df, lang=LANG)\n",
    "biden_df = filter_by_language(biden_df, lang=LANG)\n",
    "\n",
    "print(f\"Filtered trump tweets: {len(trump_df)}\")\n",
    "print(f\"Filtered biden tweets: {len(biden_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Filtro por sentimiento\n",
    "trump_df = filter_by_sentiment(trump_df, feeling='neg', threshold=0.3)\n",
    "biden_df = filter_by_sentiment(biden_df, feeling='neg', threshold=0.3)\n",
    "\n",
    "print(f\"Filtered trump tweets: {len(trump_df)}\")\n",
    "print(f\"Filtered biden tweets: {len(biden_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(trump_df['tweet'][:10].to_numpy())\n",
    "print(biden_df['tweet'][:10].to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Post processing files generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trump_file_path = f\"{GOOGLE_DRIVE_BASE_DIR}/trump_tweets.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trump_tweets = trump_df[\"tweet\"].tolist()\n",
    "with open(trump_file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "    for tweet in trump_tweets:\n",
    "        file.write(f\"{tweet}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "biden_file_path = f\"{GOOGLE_DRIVE_BASE_DIR}/biden_tweets.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "biden_tweets = biden_df[\"tweet\"].tolist()\n",
    "with open(biden_file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "    for tweet in biden_tweets:\n",
    "        file.write(f\"{tweet}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "users_file_path = f\"{GOOGLE_DRIVE_BASE_DIR}/users.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(users_file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "    for _, tweet in biden_df.iterrows():\n",
    "        file.write(f\"username: {tweet['user_screen_name']}\\ndescription: {tweet['user_description']}\\n\")\n",
    "    for _, tweet in trump_df.iterrows():\n",
    "        file.write(f\"username: {tweet['user_screen_name']}\\ndescription: {tweet['user_description']}\\n\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
